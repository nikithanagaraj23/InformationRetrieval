{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def casefolding(data):\n",
    "    return data.lower()\n",
    "\n",
    "def get_sentences(result):\n",
    "    doc   = open(\"test-collection/cacm/\"+ result + \".html\",\"r\")\n",
    "    data = doc.read()\n",
    "    data = BeautifulSoup(data, \"lxml\").text\n",
    "    data = casefolding(data)\n",
    "    sentences  = re.split(r\"\\.[\\s\\n]+ | \\n\",data)\n",
    "    sentences = [s.replace(\"\\n\",\" \").replace(\"\\t\",\" \").replace(\"\\d+\",\" \") for s in sentences]\n",
    "    return sentences\n",
    "\n",
    "def getDocWordFreq(word,document):\n",
    "    value = 0\n",
    "    if unigram_invertedlist_count.get(word):\n",
    "        for val in unigram_invertedlist_count[word][1]:\n",
    "            if(val[0]==document):\n",
    "                value = val[1]\n",
    "    return value\n",
    "\n",
    "def calculate_significant_words(sentences, document, \\\n",
    "                                query_words, inverted_index):\n",
    "    \n",
    "    significant_words = []\n",
    "    words             = []\n",
    "    sd                = len(sentences)\n",
    "    \n",
    "    if (sd < 25): thresh = 4 - 0.1 * (25 - sd)\n",
    "    \n",
    "    elif ((25 <= sd) and (sd <= 40)): thresh = 4\n",
    "    \n",
    "    else: thresh = 4 + 0.1 * (sd - 40)\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        words.extend(word_tokenize(sentence))\n",
    "    \n",
    "    for word in words:   \n",
    "        f_dw = getDocWordFreq(word, document)\n",
    "        if f_dw >= thresh: significant_words.append(word)\n",
    "            \n",
    "    significant_words.extend(query_words)\n",
    "    significant_words = list(set(significant_words))\n",
    "\n",
    "\n",
    "    return significant_words\n",
    "\n",
    "\n",
    "def calculate_significance_factor(sentences, significant_words):\n",
    "    \n",
    "    word_count = 0\n",
    "    significance_factor = {}\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        tokenized_sentence          = word_tokenize(sentence)\n",
    "        filtered_significance_words = set(tokenized_sentence)\\\n",
    "                                        .intersection(set(significant_words))\n",
    "        min_index = 100000;\n",
    "        max_index = -1;\n",
    "        \n",
    "        filtered_significance_words = [x for x in filtered_significance_words if x not in commonwords]\n",
    "    \n",
    "        for token in tokenized_sentence:\n",
    "            #print(\"token\",token)\n",
    "            if token in filtered_significance_words: \n",
    "                \n",
    "                new_max_index = max([i for i, x in enumerate(tokenized_sentence) if x == token])\n",
    "                new_min_index = min([i for i, x in enumerate(tokenized_sentence) if x == token])\n",
    "                \n",
    "                if(min_index > new_min_index):\n",
    "                    min_index = new_min_index\n",
    "                \n",
    "                if(max_index < new_max_index):\n",
    "                    max_index = new_max_index\n",
    "                \n",
    "                text_span = (max_index - min_index) + 0.0001\n",
    "        \n",
    "                count = sum([1 for w in tokenized_sentence[min_index: max_index] if w in filtered_significance_words])\n",
    "                significance_factor[sentence] = count**2/text_span\n",
    "    \n",
    "    return significance_factor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_summary(results, query):\n",
    "    query_words     = query.split(' ')\n",
    "    query_words     = [x for x in query_words if x not in commonwords]\n",
    "    significance_df = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    for result in results:\n",
    "        significance_dict = []\n",
    "        sentences         = get_sentences(result)\n",
    "        significant_words = calculate_significant_words(sentences, \n",
    "                                                        result, query_words, \n",
    "                                                        inverted_index)\n",
    "        \n",
    "        for sent, score in calculate_significance_factor(sentences, significant_words).items():\n",
    "            \n",
    "            for query_word in query_words:\n",
    "                \n",
    "                sent = sent.replace(query_word, '<b> ' + query_word + '</b>')\n",
    "        \n",
    "            significance_dict.append({'result' : result, \n",
    "                                        'significance_factor': score,\n",
    "                                         'sentence': sent})\n",
    "        #print('\\n\\n\\n')\n",
    "#             print(significance_dict)\n",
    "        #print(pd.DataFrame.from_dict(significance_dict).sort_values('significance_factor', ascending=False)[:3])\n",
    "        \n",
    "        significance_df = significance_df.append(pd.DataFrame.from_dict(significance_dict).sort_values('significance_factor', ascending=False)[:3])\n",
    "    \n",
    "    return significance_df\n",
    "\n",
    "def get_query_id_map():\n",
    "    \n",
    "    with open('./test-collection/cacm.query.txt') as f:\n",
    "        queries = f.read()\n",
    "    \n",
    "    query_ids = re.findall(r'<DOCNO> \\d+ </DOCNO>', queries)\n",
    "    query_ids = [re.findall(r'\\d+', q)[0] for q in query_ids]\n",
    "    \n",
    "    queries = re.split(r'</DOC>', queries)\n",
    "    queries = [l.replace('</DOCNO>', '').replace('\\n', ' ')\\\n",
    "               .replace('</DOC>', '').replace('<DOC>', '')\\\n",
    "               .replace('<DOCNO>', '') for l in queries]\n",
    "    \n",
    "    #queries = [re.sub(r'^\\d*\\s\\s', '',l) for l in queries]\n",
    "\n",
    "    queries = [re.sub(r'\\s{2,5}', '',l) for l in queries]\n",
    "    queries = [re.sub(r'\\d{1,2}', '',l) for l in queries]\n",
    "    \n",
    "    queries  = pd.DataFrame({'query_ids': query_ids, \n",
    "                             'queries': queries[:-1]}).set_index('query_ids')\n",
    "    \n",
    "    return query_ids,queries\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def iterate_queries(queries, path = 'baseline-runs/task1-bm25'):\n",
    "    \n",
    "    queries_ids = [f.split('.')[0].replace('Q', '') for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "    print(queries_ids)\n",
    "    for query_id in tqdm(queries_ids):\n",
    "        print(query_id)\n",
    "        query_results = pd.read_csv(path + 'Q' + query_id + '.txt', sep='\\t', names = ['qid', 'Q0', 'doc_id',\n",
    "                                                                                         'rank','score', 'system'])\n",
    "       \n",
    "        get_text_summary(list(query_results['doc_id']),\\\n",
    "                         queries.loc[queries.index == query_id, 'queries'][query_id])[['result', 'sentence']]\\\n",
    "                         .to_html('phase2-output/snippets/' + query_id + '.html',\n",
    "                                  index = False, escape = False, border = 0, max_rows = None, max_cols = None)\n",
    "        print(list(query_results['doc_id']))\n",
    "        \n",
    "        \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# significance_factor = calculate_significance_factor(sentences, significant_words)\n",
    "unigram_invertedlist_count = {}\n",
    "inverted_index = {}\n",
    "commonwords = []\n",
    "query_ids,queries = get_query_id_map()\n",
    "queries.to_csv('queries.csv')\n",
    "with open ('reusable_data/unigram_invertedlist_count.pkl', 'rb') as f: \n",
    "    unigram_invertedlist_count = pickle.load(f)\n",
    "    \n",
    "with open('reusable_data/inverted_index.pkl', 'rb') as f:\n",
    "    inverted_index = pickle.load(f)\n",
    "commonwords     = open('test-collection/common_words', \"r\")\n",
    "commonwords     = commonwords.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['38', '10', '11', '39', '13', '12', '16', '', '9', '8', '17', '15', '29', '28', '14', '58', '64', '59', '61', '49', '48', '60', '62', '63', '46', '52', '53', '47', '51', '45', '44', '50', '54', '40', '41', '55', '43', '57', '56', '42', '19', '25', '31', '6', '7', '30', '24', '18', '32', '26', '5', '4', '27', '33', '37', '23', '1', '22', '36', '20', '34', '3', '2', '35', '21']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d322dd0dd949a7b505912bd7df5cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "['CACM-2867', 'CACM-3031', 'CACM-2941', 'CACM-2470', 'CACM-3105', 'CACM-1698', 'CACM-3177', 'CACM-2582', 'CACM-0595', 'CACM-3060', 'CACM-3142', 'CACM-2247', 'CACM-2931', 'CACM-2989', 'CACM-1861', 'CACM-3148', 'CACM-0497', 'CACM-2082', 'CACM-2970', 'CACM-3054', 'CACM-2139', 'CACM-3162', 'CACM-1637', 'CACM-3033', 'CACM-2579', 'CACM-1323', 'CACM-1489', 'CACM-0321', 'CACM-2400', 'CACM-1873', 'CACM-2939', 'CACM-0483', 'CACM-0867', 'CACM-3140', 'CACM-2815', 'CACM-0718', 'CACM-2356', 'CACM-2305', 'CACM-2609', 'CACM-1352', 'CACM-2369', 'CACM-2986', 'CACM-1643', 'CACM-2912', 'CACM-1931', 'CACM-2876', 'CACM-2958', 'CACM-3014', 'CACM-2705', 'CACM-1359', 'CACM-3069', 'CACM-1382', 'CACM-1536', 'CACM-2957', 'CACM-3103', 'CACM-2733', 'CACM-0670', 'CACM-2390', 'CACM-1248', 'CACM-1867', 'CACM-2327', 'CACM-2309', 'CACM-1769', 'CACM-3052', 'CACM-2109', 'CACM-3009', 'CACM-2956', 'CACM-1958', 'CACM-2184', 'CACM-3179', 'CACM-2707', 'CACM-2480', 'CACM-2750', 'CACM-0492', 'CACM-1572', 'CACM-3008', 'CACM-2832', 'CACM-1474', 'CACM-2232', 'CACM-2229', 'CACM-2712', 'CACM-2354', 'CACM-2192', 'CACM-1625', 'CACM-3132', 'CACM-1155', 'CACM-1032', 'CACM-2196', 'CACM-1456', 'CACM-1170', 'CACM-1787', 'CACM-0441', 'CACM-1458', 'CACM-2145', 'CACM-1486', 'CACM-2903', 'CACM-2624', 'CACM-1462', 'CACM-3082', 'CACM-0849']\n",
      "10\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'significance_factor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2441\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2442\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'significance_factor'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-2e5ca3f2a1ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# significance_factor = calculate_significance_factor(sentences, significant_words)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0miterate_queries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'baseline-runs/task1-bm25/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-5452b3da6f8d>\u001b[0m in \u001b[0;36miterate_queries\u001b[0;34m(queries, path)\u001b[0m\n\u001b[1;32m     63\u001b[0m                                                                                          'rank','score', 'system'])\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         get_text_summary(list(query_results['doc_id']),                         queries.loc[queries.index == query_id, 'queries'][query_id])[['result', 'sentence']]                         .to_html('phase2-output/snippets/' + query_id + '.html',\n\u001b[0m\u001b[1;32m     66\u001b[0m                                   index = False, escape = False, border = 0, max_rows = None, max_cols = None)\n\u001b[1;32m     67\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'doc_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-5452b3da6f8d>\u001b[0m in \u001b[0;36mget_text_summary\u001b[0;34m(results, query)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#print(pd.DataFrame.from_dict(significance_dict).sort_values('significance_factor', ascending=False)[:3])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0msignificance_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignificance_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignificance_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'significance_factor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msignificance_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position)\u001b[0m\n\u001b[1;32m   3184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3185\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3186\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   2021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2023\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1971\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2442\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'significance_factor'"
     ]
    }
   ],
   "source": [
    "# significance_factor = calculate_significance_factor(sentences, significant_words)\n",
    "iterate_queries(queries, path = 'baseline-runs/task1-bm25/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
