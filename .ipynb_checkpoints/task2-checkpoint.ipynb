{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "from collections import Counter,OrderedDict\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import glob\n",
    "import pickle\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inverted_unigram_dict = dict()\n",
    "unigram_termcount = {}\n",
    "unigram_corpus_count = 0\n",
    "path = 'corpus'\n",
    "smoothening_factor = 0.35\n",
    "\n",
    "\n",
    "def casefolding(data):\n",
    "    return data.lower()\n",
    "\n",
    "def punctuationHandling(data):\n",
    "    regex = r\"(?<!\\d)[.,;:*!\\\"\\'#$%&()+/<=>?@[\\]_^`~{|}∑α](?!\\d)\"\n",
    "    data = re.sub(regex, \"\", data, 0)\n",
    "    data = re.sub(r'\\d+', '', data)\n",
    "    regex = r\"[;:*!\\\"\\'#$%&()+/<=>?@[\\]_^`~{|}]\"\n",
    "    data = re.sub(regex, \"\", data, 0)\n",
    "#     data = data.strip(string.punctuation)\n",
    "    return data\n",
    "\n",
    "def removeWhitespace(data):\n",
    "    data = ' '.join(data.split())\n",
    "    return data\n",
    "\n",
    "def createCorpusFile(heading,maincontent):\n",
    "    fo = open(\"corpus/\"+str(heading)+\".txt\", \"w\")\n",
    "    fo.write(maincontent)\n",
    "    fo.close()\n",
    "\n",
    "def parseDocs():\n",
    "    for filename in glob.glob(\"test-collection/cacm/*.html\"):\n",
    "        fo = open(filename, \"r\")\n",
    "        heading = os.path.basename(filename).split(\".\")[0]\n",
    "        data = fo.read()\n",
    "        maincontent = BeautifulSoup(data, \"lxml\").text\n",
    "        maincontent = casefolding(maincontent)\n",
    "        maincontent = punctuationHandling(maincontent)\n",
    "        maincontent = removeWhitespace(maincontent)\n",
    "        createCorpusFile(heading,maincontent)\n",
    "        \n",
    "def createIndexDict(file, ngram_dict, inverted_dict):\n",
    "    for key,value in ngram_dict.items():\n",
    "        if (inverted_dict.get(key)):\n",
    "            inverted_dict.get(key).append((os.path.basename(file).split(\".\")[0],value))\n",
    "        else:\n",
    "            inverted_dict[key] = [(os.path.basename(file).split(\".\")[0],value)]\n",
    "    return inverted_dict\n",
    "\n",
    "def getInvertedListCount(index_list):\n",
    "    invertedlist_count = {}\n",
    "    for key,val in index_list.items():\n",
    "        invertedlist_count[key] = [len(val),val]\n",
    "    return invertedlist_count\n",
    "\n",
    "def getDocWordFreq(word,document):\n",
    "    value = 0\n",
    "    if unigram_invertedlist_count.get(word):\n",
    "        for val in unigram_invertedlist_count[word][1]:\n",
    "            if(val[0]==document):\n",
    "                value = val[1]\n",
    "    return value\n",
    "\n",
    "def getCorpusWordFreq(word):\n",
    "    if unigram_invertedlist_count.get(word):\n",
    "        return unigram_invertedlist_count[word][0]\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def query_preprocessor(filepath = 'test-collection/cacm.query.txt'):\n",
    "    with open(filepath) as f: queries = f.read()\n",
    "    queries = [l.replace('</DOCNO>', '').replace('\\n', ' ').replace('</DOC>', '').replace('<DOC>', '')[1:] for l in queries.split('<DOCNO>')]\n",
    "    queries = [re.sub(r'^\\d*\\s\\s', '',l) for l in queries]\n",
    "    queries = [s.lower() for s in queries]\n",
    "    queries = [punctuationHandling(query) for query in queries]\n",
    "    queries = [removeWhitespace(query) for query in queries]\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pseudo_relavance(query,bm25_score_dict):\n",
    "    k = 10\n",
    "    #Generate query vector\n",
    "    query_vector = {}\n",
    "    query_list = query.split(\" \")\n",
    "    \n",
    "    for query_word in query_list:\n",
    "        if(query_vector.get(query_word)):\n",
    "            query_vector[query_word] += 1\n",
    "        else:\n",
    "            query_vector[query_word] = 1\n",
    "            \n",
    "    for key,val in unigram_invertedlist_count.items():\n",
    "        if not query_vector.get(key):\n",
    "            query_vector[key] = 0\n",
    "    relevance_vector,relevance_vector_magnitude = generate_relevance_vector(query,bm25_score_dict,k)\n",
    "    \n",
    "    non_relevance_vector,non_relevance_vector_magnitude = generate_non_relevance_vector(query,bm25_score_dict,k)\n",
    "\n",
    "    expanded_q = query_expansion(query,query_vector,relevance_vector,relevance_vector_magnitude,\n",
    "                    non_relevance_vector,non_relevance_vector_magnitude)\n",
    "   \n",
    "    return(expanded_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_relevance_vector(query,bm25_score_dict,k):\n",
    "    sorted_doc = dict(sorted(bm25_score_dict.items(), key=operator.itemgetter(1), reverse=True)[:k])\n",
    "    relevance_vector = {}\n",
    "    for key,val in sorted_doc.items():\n",
    "        with open ('corpus/'+key+'.txt', 'r') as f: \n",
    "            doc_list = f.read().split()\n",
    "            for term in doc_list:\n",
    "                if(relevance_vector.get(term)):\n",
    "                    relevance_vector[term] += 1\n",
    "                else:\n",
    "                    relevance_vector[term] = 1\n",
    "\n",
    "            for token,val in unigram_invertedlist_count.items():\n",
    "                if not relevance_vector.get(token):\n",
    "                        relevance_vector[token] = 0\n",
    "                        \n",
    "    relevance_vector_magnitude = 0\n",
    "    for key,val in relevance_vector.items():\n",
    "        relevance_vector_magnitude += float(val**2)\n",
    "    \n",
    "    relevance_vector_magnitude = math.sqrt(relevance_vector_magnitude)\n",
    "    return(relevance_vector,relevance_vector_magnitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_non_relevance_vector(query,bm25_score_dict,k):\n",
    "    sorted_doc = dict(sorted(bm25_score_dict.items(), key=operator.itemgetter(1), reverse=True)[k:])\n",
    "    non_relevance_vector = {}\n",
    "    for key,val in sorted_doc.items():\n",
    "        with open ('corpus/'+key+'.txt', 'r') as f: \n",
    "            doc_list = f.read().split()\n",
    "            for term in doc_list:\n",
    "                if(non_relevance_vector.get(term)):\n",
    "                    non_relevance_vector[term] += 1\n",
    "                else:\n",
    "                    non_relevance_vector[term] = 1\n",
    "\n",
    "            for token,val in unigram_invertedlist_count.items():\n",
    "                if not non_relevance_vector.get(token):\n",
    "                        non_relevance_vector[token] = 0\n",
    "                        \n",
    "    non_relevance_vector_magnitude = 0\n",
    "    for key,val in non_relevance_vector.items():\n",
    "        non_relevance_vector_magnitude += float(val**2)\n",
    "    \n",
    "    non_relevance_vector_magnitude = math.sqrt(non_relevance_vector_magnitude)\n",
    "    return(non_relevance_vector,non_relevance_vector_magnitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_expansion(query,query_vector,relevance_vector,relevance_vector_magnitude,\\\n",
    "                    non_relevance_vector,non_relevance_vector_magnitude):\n",
    "    query_expansion_dict = {}\n",
    "    for term,val in unigram_invertedlist_count.items():\n",
    "        query_expansion_dict[term] = query_vector[term]+ (0.5/relevance_vector_magnitude) * relevance_vector[term] -\\\n",
    "        (0.15/non_relevance_vector_magnitude) * non_relevance_vector[term]\n",
    "    \n",
    "    query_expansion_dict = dict(sorted(query_expansion_dict.items(), key=operator.itemgetter(1), reverse=True))\n",
    "    \n",
    "    expanded_query = query\n",
    "    no_extra_query_terms = 15\n",
    "    for i in range(no_extra_query_terms):\n",
    "        term =  list(query_expansion_dict.keys())[i]\n",
    "        if term not in query:\n",
    "            expanded_query+= \" \"+term\n",
    "    return expanded_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_new_queries():\n",
    "    for old_query in range(len(all_queries)):\n",
    "        expanded_q = pseudo_relavance(all_queries[old_query],bm25_score_dict)\n",
    "        expanded_query_list.append(expanded_q)\n",
    "        \n",
    "    return expanded_query_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeToFile(queryid,queryname,lmscore_dict,folder_name,system_name):\n",
    "    fo = open(\"baseline-runs/\"+folder_name+\"/\"+ \"Q\" + str(queryid) +\".txt\", \"w\")\n",
    "    for key,val in lmscore_dict.items():\n",
    "        rank = list(lmscore_dict.keys()).index(key)+1\n",
    "        fo.write(str(queryid)+\"\\tQ0\\t\"+str(key)+\"\\t\"+str(rank)+\"\\t\"+str(val)+\"\\t\"+ system_name +\"\\n\")\n",
    "    fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CACM-1519': 24.64291001264796, 'CACM-1605': 23.148162233549694, 'CACM-1410': 22.33330316789089, 'CACM-1591': 22.29077525815539, 'CACM-1033': 22.288959392145333, 'CACM-1506': 21.989576069246546, 'CACM-1161': 21.101968184738794, 'CACM-2319': 20.927837849632983, 'CACM-0585': 20.79347097377166, 'CACM-2379': 20.548433949383885, 'CACM-1698': 20.509085403312735, 'CACM-1680': 20.394312018199077, 'CACM-1938': 20.27476212484826, 'CACM-2054': 20.156604992450905, 'CACM-3048': 20.112135059644178, 'CACM-1844': 19.64595985147516, 'CACM-1264': 19.588225124500664, 'CACM-1750': 19.57764677467663, 'CACM-1523': 19.44969520614981, 'CACM-3127': 19.300844835949388, 'CACM-1544': 19.188042794803522, 'CACM-3025': 19.088333428950925, 'CACM-2371': 19.062308896129696, 'CACM-2357': 19.002872646227104, 'CACM-2380': 18.960415721057554, 'CACM-2947': 18.8593754495853, 'CACM-1168': 18.649673825895533, 'CACM-1315': 18.431842043017898, 'CACM-2535': 18.31534295256021, 'CACM-1827': 18.041805239516613, 'CACM-0637': 17.83089311847446, 'CACM-2541': 17.73120360694545, 'CACM-2764': 17.641970032738698, 'CACM-0698': 17.5890638570609, 'CACM-1657': 17.469620165199395, 'CACM-1885': 17.465527233014207, 'CACM-1647': 17.43917482294557, 'CACM-1685': 17.423344213074998, 'CACM-1236': 17.41811143229179, 'CACM-0971': 17.359133175995442, 'CACM-2629': 17.353617964954726, 'CACM-2740': 17.298578456308963, 'CACM-2948': 17.271610691857237, 'CACM-0414': 17.244737283970835, 'CACM-2542': 17.015039944728564, 'CACM-0252': 16.957436265433138, 'CACM-2424': 16.893628137452534, 'CACM-1195': 16.701252348225204, 'CACM-2681': 16.55727683081463, 'CACM-2950': 16.467928598559396, 'CACM-2622': 16.435200265343695, 'CACM-2398': 16.393794848816697, 'CACM-2219': 16.349286305755157, 'CACM-2624': 16.307750692619003, 'CACM-1226': 16.184693924139594, 'CACM-1482': 15.968916582955758, 'CACM-1697': 15.947697822356787, 'CACM-2560': 15.93533027388697, 'CACM-1805': 15.877655104496265, 'CACM-3137': 15.796080534212788, 'CACM-2951': 15.777465274873965, 'CACM-2878': 15.764448440729694, 'CACM-2201': 15.753339996804899, 'CACM-2390': 15.740783151689143, 'CACM-2188': 15.734869705600449, 'CACM-1173': 15.709836931203137, 'CACM-1304': 15.687314525688596, 'CACM-2920': 15.630064488226907, 'CACM-1179': 15.60537950406104, 'CACM-2358': 15.531731655626373, 'CACM-1341': 15.48358155417515, 'CACM-2003': 15.452701232084145, 'CACM-1163': 15.451647190933024, 'CACM-2372': 15.427106673991037, 'CACM-1534': 15.349507044224815, 'CACM-1747': 15.348768538976742, 'CACM-1472': 15.346639255614296, 'CACM-2378': 15.266074114031314, 'CACM-0696': 15.100097782140125, 'CACM-2288': 15.079637831712686, 'CACM-2946': 15.007237963347896, 'CACM-2500': 14.9563337031169, 'CACM-2632': 14.906993009547557, 'CACM-0972': 14.893072459401015, 'CACM-2917': 14.845253336100463, 'CACM-2370': 14.725970725396719, 'CACM-2153': 14.70674143141145, 'CACM-1753': 14.704672750409475, 'CACM-0202': 14.682926430685027, 'CACM-3068': 14.65174712210699, 'CACM-1542': 14.605085850737813, 'CACM-1571': 14.549373156690258, 'CACM-3089': 14.51820724600212, 'CACM-1034': 14.510295375513419, 'CACM-2536': 14.453758792917206, 'CACM-2184': 14.396141069848673, 'CACM-2344': 14.360845284736424, 'CACM-1533': 14.324764793862025, 'CACM-2796': 14.317257421260958, 'CACM-1225': 14.28622953658401}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'udo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-833a560df323>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_expanded_queries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mbm25_score_dict_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpopulate_bm25\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_expanded_queries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbm25_score_dict_expanded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-3a8bbd6e6196>\u001b[0m in \u001b[0;36mpopulate_bm25\u001b[0;34m(queryString)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdocid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mdocument_bm25_score_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_bm25\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mqueryString\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument_bm25_score_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mdocument_bm25_score_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument_bm25_score_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdocument_bm25_score_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-2e3dc5e918bb>\u001b[0m in \u001b[0;36mget_bm25\u001b[0;34m(document, query, document_bm25_score_dict)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#number of docs containing the term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munigram_invertedlist_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_word\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#Total number of documents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'udo'"
     ]
    }
   ],
   "source": [
    "expanded_query_list = []\n",
    "for filename in glob.glob(\"corpus/*.txt\"):\n",
    "    fo = open(filename, \"r\")\n",
    "    data = fo.read()\n",
    "    tokens = nltk.word_tokenize(data)\n",
    "    unigramlist = nltk.word_tokenize(data)\n",
    "    unigram_termcount[os.path.basename(filename).split(\".\")[0]] = len(unigramlist)\n",
    "    unigram_corpus_count = unigram_corpus_count + len(unigramlist)\n",
    "    unigram_dict = Counter(unigramlist)\n",
    "    inverted_unigram_dict = createIndexDict(filename, unigram_dict, inverted_unigram_dict)\n",
    "    fo.close()\n",
    "    \n",
    "unigram_invertedlist_count = getInvertedListCount(inverted_unigram_dict)\n",
    "number_of_docs = len(glob.glob('corpus/*.txt'))\n",
    "with open('reusable_data/unigram_invertedlist_count.pkl', 'wb') as f:\n",
    "    pickle.dump(unigram_invertedlist_count, f)\n",
    "    \n",
    "with open('reusable_data/inverted_index.pkl', 'wb') as f:\n",
    "    pickle.dump(inverted_unigram_dict, f)\n",
    "\n",
    "all_queries = query_preprocessor()[1:]\n",
    "\n",
    "for i in range(len(all_queries)):\n",
    "    print(all_queries[i])\n",
    "    bm25_score_dict = populate_bm25(all_queries[i])\n",
    "    writeToFile(i+1,all_queries[i],bm25_score_dict,\"task1-bm25\",\"ccisneu_wordunigram_BM25\")\n",
    "\n",
    "all_expanded_queries = get_all_new_queries()\n",
    "\n",
    "for i in range(len(all_expanded_queries)):\n",
    "    bm25_score_dict_expanded = populate_bm25(all_expanded_queries[i])\n",
    "    writeToFile(i+1,all_queries[i],bm25_score_dict_expanded,\"task2-bm25-pseudo-relevance\",\"ccisneu_wordunigram_BM25_PSEUDO_RELEVANCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
